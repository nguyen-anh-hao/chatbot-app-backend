#!/usr/bin/env python3
"""
RAG Recipe Model for Production Use
ÄÃ³ng gÃ³i mÃ´ hÃ¬nh RAG Ä‘á»ƒ sá»­ dá»¥ng trong production vá»›i tá»‘c Ä‘á»™ cao
"""

import pickle
import joblib
from pathlib import Path
import json
import numpy as np
import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer
import time
from typing import List, Dict, Optional

class RAGRecipeModel:
    """
    MÃ´ hÃ¬nh RAG Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u cho production
    
    Usage:
        # Láº§n Ä‘áº§u tiÃªn: táº¡o vÃ  lÆ°u mÃ´ hÃ¬nh
        model = RAGRecipeModel()
        model.create_and_save_model(df, embeddings)
        
        # Trong production: load vÃ  sá»­ dá»¥ng
        model = RAGRecipeModel()
        model.load_model()
        results = model.search("chicken rice")
    """
    
    def __init__(self, model_dir: str = "./model_artifacts"):
        self.model_dir = Path(model_dir)
        self.sentence_model = None
        self.faiss_index = None
        self.recipes_df = None
        self.embeddings = None
        self.metadata = None
        
    def create_and_save_model(self, df: pd.DataFrame, embeddings: np.ndarray, 
                             model_name: str = "all-MiniLM-L6-v2"):
        """
        Táº¡o vÃ  lÆ°u mÃ´ hÃ¬nh tá»« dá»¯ liá»‡u gá»‘c
        
        Args:
            df: DataFrame chá»©a dá»¯ liá»‡u recipes
            embeddings: Numpy array chá»©a embeddings
            model_name: TÃªn cá»§a sentence transformer model
        """
        # Táº¡o thÆ° má»¥c
        self.model_dir.mkdir(exist_ok=True)
        
        # LÆ°u DataFrame
        df.to_pickle(self.model_dir / "recipes_df.pkl")
        
        # LÆ°u embeddings
        np.save(self.model_dir / "embeddings.npy", embeddings)
        
        # Táº¡o vÃ  lÆ°u FAISS index
        dimension = embeddings[0].shape[0]
        index = faiss.IndexFlatL2(dimension)
        index.add(embeddings)
        faiss.write_index(index, str(self.model_dir / "recipes_faiss.index"))
        
        # LÆ°u metadata
        metadata = {
            "model_name": model_name,
            "dimension": dimension,
            "num_recipes": len(df),
            "created_at": str(pd.Timestamp.now()),
            "version": "1.0"
        }
        
        with open(self.model_dir / "metadata.json", "w") as f:
            json.dump(metadata, f, indent=2)
            
        print(f"âœ… Model saved to {self.model_dir}")
        print(f"ğŸ“Š {len(df)} recipes, {dimension}D embeddings")
        
    def load_model(self, lazy_load: bool = True) -> Dict:
        """
        Load mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u
        
        Args:
            lazy_load: Náº¿u True, chá»‰ load khi cáº§n thiáº¿t (tiáº¿t kiá»‡m memory)
            
        Returns:
            Dictionary chá»©a metadata cá»§a mÃ´ hÃ¬nh
        """
        if not self.model_dir.exists():
            raise FileNotFoundError(f"âŒ Model directory {self.model_dir} not found")
            
        # Load metadata
        with open(self.model_dir / "metadata.json", "r") as f:
            self.metadata = json.load(f)
            
        if not lazy_load:
            self._load_all_components()
        else:
            print("ğŸš€ Model metadata loaded. Components will be loaded on demand.")
            
        print(f"âœ… Model ready! {self.metadata['num_recipes']} recipes available.")
        return self.metadata
        
    def _load_all_components(self):
        """Load táº¥t cáº£ components cá»§a mÃ´ hÃ¬nh"""
        if self.sentence_model is None:
            print("ğŸ“¥ Loading sentence transformer...")
            self.sentence_model = SentenceTransformer(self.metadata["model_name"])
            
        if self.recipes_df is None:
            print("ğŸ“¥ Loading recipes dataframe...")
            self.recipes_df = pd.read_pickle(self.model_dir / "recipes_df.pkl")
            
        if self.embeddings is None:
            print("ğŸ“¥ Loading embeddings...")
            self.embeddings = np.load(self.model_dir / "embeddings.npy")
            
        if self.faiss_index is None:
            print("ğŸ“¥ Loading FAISS index...")
            self.faiss_index = faiss.read_index(str(self.model_dir / "recipes_faiss.index"))
            
    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """
        TÃ¬m kiáº¿m recipes dá»±a trÃªn query
        
        Args:
            query: CÃ¢u truy váº¥n
            top_k: Sá»‘ lÆ°á»£ng káº¿t quáº£ tráº£ vá»
            
        Returns:
            List cÃ¡c dictionary chá»©a thÃ´ng tin recipe
        """
        # Lazy loading
        if self.sentence_model is None:
            self.sentence_model = SentenceTransformer(self.metadata["model_name"])
        if self.faiss_index is None:
            self.faiss_index = faiss.read_index(str(self.model_dir / "recipes_faiss.index"))
        if self.recipes_df is None:
            self.recipes_df = pd.read_pickle(self.model_dir / "recipes_df.pkl")
            
        # Encode query
        start_time = time.time()
        query_vector = self.sentence_model.encode([query])
        encode_time = time.time() - start_time
        
        # Search
        start_time = time.time()
        D, I = self.faiss_index.search(np.array(query_vector), top_k)
        search_time = time.time() - start_time
        
        # Format results
        results = []
        for i, (distance, idx) in enumerate(zip(D[0], I[0])):
            recipe_info = {
                'rank': i + 1,
                'similarity_score': 1 / (1 + distance),
                'title': self.recipes_df.iloc[idx]['Title'],
                'ingredients': self.recipes_df.iloc[idx]['Cleaned_Ingredients'],
                'instructions': self.recipes_df.iloc[idx]['Instructions'],
                'image_name': self.recipes_df.iloc[idx]['Image_Name'],
                'encode_time': encode_time,
                'search_time': search_time
            }
            results.append(recipe_info)
            
        return results
    
    def batch_search(self, queries: List[str], top_k: int = 5) -> List[List[Dict]]:
        """
        TÃ¬m kiáº¿m nhiá»u queries cÃ¹ng lÃºc (tá»‘i Æ°u hÆ¡n)
        
        Args:
            queries: List cÃ¡c cÃ¢u truy váº¥n
            top_k: Sá»‘ lÆ°á»£ng káº¿t quáº£ cho má»—i query
            
        Returns:
            List of lists chá»©a káº¿t quáº£ cho tá»«ng query
        """
        # Lazy loading
        if self.sentence_model is None:
            self.sentence_model = SentenceTransformer(self.metadata["model_name"])
        if self.faiss_index is None:
            self.faiss_index = faiss.read_index(str(self.model_dir / "recipes_faiss.index"))
        if self.recipes_df is None:
            self.recipes_df = pd.read_pickle(self.model_dir / "recipes_df.pkl")
            
        # Encode táº¥t cáº£ queries cÃ¹ng lÃºc
        query_vectors = self.sentence_model.encode(queries)
        
        all_results = []
        for i, query_vector in enumerate(query_vectors):
            D, I = self.faiss_index.search(np.array([query_vector]), top_k)
            
            results = []
            for j, (distance, idx) in enumerate(zip(D[0], I[0])):
                recipe_info = {
                    'rank': j + 1,
                    'similarity_score': 1 / (1 + distance),
                    'title': self.recipes_df.iloc[idx]['Title'],
                    'ingredients': self.recipes_df.iloc[idx]['Cleaned_Ingredients'],
                    'instructions': self.recipes_df.iloc[idx]['Instructions'],
                    'image_name': self.recipes_df.iloc[idx]['Image_Name']
                }
                results.append(recipe_info)
            all_results.append(results)
            
        return all_results
    
    def get_recipe_by_name(self, recipe_name: str, top_k: int = 5) -> List[Dict]:
        """
        TÃ¬m kiáº¿m theo tÃªn mÃ³n Äƒn
        
        Args:
            recipe_name: TÃªn mÃ³n Äƒn
            top_k: Sá»‘ lÆ°á»£ng káº¿t quáº£
            
        Returns:
            List cÃ¡c dictionary chá»©a thÃ´ng tin recipe
        """
        if self.recipes_df is None:
            self.recipes_df = pd.read_pickle(self.model_dir / "recipes_df.pkl")
            
        matching_recipes = self.recipes_df[
            self.recipes_df['Title'].str.contains(recipe_name, case=False, na=False)
        ]
        
        if matching_recipes.empty:
            return []
            
        results = []
        for idx, recipe in matching_recipes.head(top_k).iterrows():
            recipe_info = {
                'title': recipe['Title'],
                'ingredients': recipe['Cleaned_Ingredients'],
                'instructions': recipe['Instructions'],
                'image_name': recipe['Image_Name']
            }
            results.append(recipe_info)
            
        return results
    
    def get_stats(self) -> Dict:
        """
        Láº¥y thá»‘ng kÃª vá» mÃ´ hÃ¬nh
        
        Returns:
            Dictionary chá»©a thá»‘ng kÃª
        """
        if self.recipes_df is None:
            self.recipes_df = pd.read_pickle(self.model_dir / "recipes_df.pkl")
            
        stats = {
            "total_recipes": len(self.recipes_df),
            "model_size_mb": sum(f.stat().st_size for f in self.model_dir.glob("*")) / (1024 * 1024),
            "created_at": self.metadata["created_at"] if self.metadata else "Unknown",
            "version": self.metadata["version"] if self.metadata else "Unknown"
        }
        return stats

# Utility functions cho production
def benchmark_search(model: RAGRecipeModel, queries: List[str], iterations: int = 10):
    """
    Benchmark tá»‘c Ä‘á»™ search
    """
    print("ğŸ”¥ Benchmarking search performance...")
    
    total_times = []
    for i in range(iterations):
        start_time = time.time()
        for query in queries:
            model.search(query, top_k=5)
        total_time = time.time() - start_time
        total_times.append(total_time)
        
    avg_time = np.mean(total_times)
    avg_per_query = avg_time / len(queries)
    
    print(f"ğŸ“Š Average time for {len(queries)} queries: {avg_time:.3f}s")
    print(f"ğŸ“Š Average time per query: {avg_per_query:.3f}s")
    print(f"ğŸ“Š Queries per second: {1/avg_per_query:.1f}")
    
    return {
        "avg_total_time": avg_time,
        "avg_per_query": avg_per_query,
        "queries_per_second": 1/avg_per_query
    }

if __name__ == "__main__":
    # Demo usage
    print("ğŸš€ RAG Recipe Model Demo")
    
    # Load model
    model = RAGRecipeModel()
    
    try:
        metadata = model.load_model()
        print(f"ğŸ“ˆ Model Stats: {model.get_stats()}")
        
        # Test search
        results = model.search("chicken and rice", top_k=3)
        print(f"\nğŸ” Search results for 'chicken and rice':")
        for result in results:
            print(f"  {result['rank']}. {result['title']} (Score: {result['similarity_score']:.3f})")
            
        # Benchmark
        test_queries = ["chicken rice", "pasta", "dessert", "vegetarian", "spicy"]
        benchmark_search(model, test_queries, iterations=5)
        
    except FileNotFoundError:
        print("âŒ Model not found. Please run the notebook to create the model first.")
